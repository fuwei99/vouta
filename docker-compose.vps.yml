version: '3.8'

services:
  openai-to-gemini:
    build: .
    container_name: vertex2openai
    ports:
      # Map host port 8050 to container port 7860
      - "8050:7860"
    volumes:
      # Mount credentials directory for service account JSON files
      - ./credentials:/app/credentials:ro
      # Optional: Mount logs directory for persistent logs
      - ./logs:/app/logs
    environment:
      # Directory where credential files are stored
      - CREDENTIALS_DIR=/app/credentials

      # REQUIRED: Set a secure API key for authentication
      - API_KEY=${API_KEY:-your_secure_api_key_here}

      # Credential methods (choose ONE):
      # Option 1: Vertex Express API Key
      - VERTEX_EXPRESS_API_KEY=${VERTEX_EXPRESS_API_KEY:-}

      # Option 2: Service Account JSON content (comma-separated for multiple)
      - GOOGLE_CREDENTIALS_JSON=${GOOGLE_CREDENTIALS_JSON:-}

      # Google Cloud Project settings (optional, auto-detected if not set)
      - GCP_PROJECT_ID=${GCP_PROJECT_ID:-}
      - GCP_LOCATION=${GCP_LOCATION:-us-central1}

      # Optional settings
      - ROUNDROBIN=${ROUNDROBIN:-false}
      - FAKE_STREAMING=${FAKE_STREAMING:-false}
      - FAKE_STREAMING_INTERVAL=${FAKE_STREAMING_INTERVAL:-1.0}

      # Production optimizations
      - PYTHONUNBUFFERED=1
      - WORKERS=${WORKERS:-1}
    restart: unless-stopped
    # Resource limits for VPS deployment
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Security settings
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
    # Drop capabilities
    cap_drop:
      - ALL
    cap_add:
      - SETUID
      - SETGID

  # Optional: Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: vertex2openai-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - openai-to-gemini
    restart: unless-stopped
    profiles:
      - with-nginx

  # Optional: Watchtower for automatic updates
  watchtower:
    image: containrrr/watchtower
    container_name: vertex2openai-watchtower
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: --interval 3600 --cleanup vertex2openai
    restart: unless-stopped
    profiles:
      - with-watchtower